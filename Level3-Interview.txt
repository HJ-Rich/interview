.class 파일처럼 형상관리 대상이 아닌 파일이 commit & push 되었을 때 어떻게 대처할 수 있을까요?

git rm 명령어를 사용하여 해결할 수 있습니다.
git rm 명령어는 index에서 제거하는 명령입니다.
--cached 옵션을 추가하여 working tree에서도 삭제할지, 아니면 남겨둘지 선택할 수 있습니다.
index에서 삭제하는 작업을 완료한 후에는 .gitignore 설정을 통해 재차 staging 되지 않도록 처리해두어야 합니다.

서버 접속 정보나 저작권 위반 소지가 있는 데이터가 리모트에 push된 채로 작업하다가 뒤늦게 발견했다면 어떻게 대처할 수 있을까요?

크게 세 가지 작업을 진행해야 합니다.
첫째로 형상관리 대상에서 제외해야 합니다.
둘째로 이전 커밋 히스토리들을 Rewrite해야 합니다.
셋째로 유출된 접속 정보를 파기하거나 변경해야 합니다.
첫번째와 두번째 작업은 git filter-branch 명령어와 --index-filter 옵션을 이용해 수행할 수 있습니다.
private 리포지토리에서 진행하던 사이드 프로젝트를 public으로 전환하는 과정에서
민감 정보를 담은 application.yml 파일을 모든 커밋 이력에서 제거하기 위해 filter-branch 명령어를 사용해봤습니다.
git-scm 문서에서도 반복 강조하는 부분이 이 명령어는 성능 이슈도 있고 자잘한 버그도 있으니 가급적 사용하지 말라고 합니다.
제가 이 명령어를 사용해야 했던 상황은 재작성되어야 할 커밋 이력이 많지 않았기에 괜찮았지만
만약 상당히 많은 커밋들을 모두 재작성해야 하는 상황이었다면 그래도 이 명령어를 사용했겠지만 많이 부담스러웠을 것 같습니다.

자신만의 라이브러리를 만들어 배포해본 경험이 있나요?

HttpServletRequest를 전달받아, Bearer Token을 반환하는 라이브러리를 만들어서 jitpack으로 배포해보았습니다.
여러 프로젝트에서 반복해서 사용되는 코드인데, 매번 복사 붙여넣기로 옮겨야하는 점이 번거로웠습니다.
또한 한 곳에서 관리되지 않기에, 수정이 필요할 경우 모든 프로젝트에 각각 들어가서 수정해야 하는 점도 불편했습니다.
Spring Security OAuth 라이브러리에서 제공하는 DefaultBearerTokenResolver를 일부 수정해서 만들었습니다.
다른 사람도 사용할 수 있게 배포한다고 생각하니 테스트 코드나 변수명, 클래스명 등등 모두 더 신경써서 작성하게 되는 경험을 해봤습니다.

정적 분석 도구를 사용해본 경험이 있나요?

Github Actions, Jacoco, SonarQube를 이용한 정적 분석을 수행해본 적 있습니다.
EC2 인스턴스를 생성하고, SonarQube, PostgreSQL을 설치해서 구축한뒤,
Github Actions와 연동하여 PR 생성, 머지 시점마다 자동으로 정적 분석을 수행하게 구축해보았습니다.
SonarQube의 인상적이었던 정적 분석 중 한 가지는
팀내 의견 조율을 위해 일시적으로 @Disabled 처리해두었던 테스트에 대해
왜 @Disabled 처리했는지 주석으로 설명을 달거나 아니면 제거하라는 제안이었습니다.
당시에 소규모 팀 프로젝트였기에 모두가 이 상황에 대해 인지하고 있긴 했지만,
원칙적으로 다른 개발자들과의 소통이라는 측면에서 충분히 일리있는 제안으로 이해되었고,
이런 부분까지 탐지하고 제안해준다는 점이 인상깊었습니다.
SonarQube에서 Issue로 제기해준 내용들을 살펴보며 더 깨끗한 코드를 작성할 수 있게 될 뿐만 아니라
다른 개발자들과의 더 나은 협업을 위해서 어떻게 코드를 작성해야하는지 더 이해할 수 있었습니다.

CI 가 무엇인가요? 경험해본 적 있으신가요?

CI는 Continuous Integration 의 약자로 2010년 제즈 험블과 데이빗 팔리에 의해 제안되었습니다.
CI의 핵심 개념은 여러 개발자들이 함께 일하는 시스템의 상태에 대해 공유된 정확한 관점을 유지하고 배포하는 것입니다.
최초 제안자인 데이빗 팔리의 CI는 브랜칭 전략을 사용할 경우 이를 CI로 인정할 수 없다는 다소 엄격한 스탠스인데요,
프로젝트를 진행하며 경험한 CI는 이보다는 다소 완화된 CI 정책을 적용하여 진행해보았습니다.
먼저 브랜칭 전략을 사용하되 Github Actions를 이용해 PR 생성 시 자동으로 머지된 결과로 빌드 및 테스트가 수행되고 피드백을 받을 수 있게 구성했습니다.
또한 기능 개발이 진행중이더라도 해당 브랜치를 드러냄으로써, 작업중인 내용을 다른 개발자들도 확인할 수 있게 했습니다.
핵심 기능에 대해서는 Draft 상태로 PR을 Open해두고 추가작업을 하는 식으로 더 잦은 CI를 시도해본 바 있습니다.
현재 작업중인 코드가 병합되어서도 잘 동작하리라는 추측이 아닌 확인을 해야 한다는 CI 개념의 가치는 충분히 공감됩니다.
또한 자동화된 병합 및 테스트, 피드백이 구성되었을 때 이를 통한 빠른 수정은 개발 프로세스에 큰 도움이 되었습니다.

데이빗 팔리는 왜 Git Flow가 CI/CD로 인정하지 않았나요?

첫째로 피드백이 늦다는 점입니다.
Git Flow는 기능단위별로 브랜치를 생성해서 해당 브랜치에서 개발을 완료한 후에 병합시키는 작업 방식입니다.
이 경우, 해당 브랜치의 기능개발이 완료된 이후에야 병합하고, 피드백을 받을 수 있게 됩니다.
이처럼 늦은 피드백은 잘못 개발하고 있었을 경우 큰 비용으로 이어지기도 하고, 병합 시점에 많은 비용을 치러야하기도 합니다.
그리고 이는 곧 배포의 지연으로 이어지기에 크리티컬한 이슈라 할 수 있습니다.
반면 데이빗 팔리의 CI는 최소 하루에 한 번, 실제론 하루에도 여러차례 pull, push를 하며 빠르게 피드백을 받는 것을 의미합니다.
둘째로 Git Flow는 변화를 숨긴다는 점입니다.
개발자들의 협업의 최종관심사는 고객에게 전달되는 main 브랜치 하나인데, 안정성을 위해 변화를 숨기고 속도를 양보하는 것이 데이빗 팔리가 바라보는 Git Flow입니다.
서로 다른 feature 브랜치에서 개발을 진행하면 서로 어떤 변경이 있는지, 이들간 충돌은 없는지 병합 시점이 되어서야 확인할 수 있게 됩니다.
반면 데이빗 팔리의 CI는 하루에도 몇번씩, 협업 대상 리모트에 pull, push를 수행하기에,
다른 개발자들의 개발 내용도 수시로 확인하며 변화가 드러나게 되고, 이러한 드러난 변화가 배포해도 안전하다는 신호를 전달한다는 것이 데이빗 팔리의 주장입니다.

JpaRepository 대신 Repository를 사용한 이유가 있나요?

첫째로 필요한 메시지만 개방하기 위함이었습니다.
객체의 개방된 메서드들은 각각 책임을 의미하고, 이 책임이 모여 하나의 역할을 이루게 됩니다.
따라서 어떤 메서드가 열려있는지는 해당 객체를 정의내리는 중요한 지표라고 할 수 있습니다.
JpaRepository를 확장할 경우 프로덕션에서 사용되는지 여부와 상관 없이 기본으로 20여개의 메서드가 개방됩니다.
반면 Repository를 확장할 경우, 실제 프로덕션에서 사용되는 메서드만 선언해서 사용해야 합니다.
이처럼 실제 사용되는, 실제 필요한 메서드만 개방하는 것은 다른 개발자들에게도 이 객체의 역할을 전달하는 역할을 할 수 있다고 생각합니다.
둘째로 명세로서의 인터페이스를 충실하게 유지하기 위함이었습니다.
JpaRepository를 확장하는 클래스 역시 인터페이스인데,
사용하지 않는 메서드들이 정의되어 있다면, 해당 인터페이스의 규약을 제대로 전달하지 못하는 것이라 생각했습니다.
마지막으로 테스트 더블 생성 용이성을 가져가기 위함이었습니다.
직접 경험해보진 못했지만 CQRS 관련 테스트를 위해선 Repository의 테스트 더블을 만들 일이 있다고 들었습니다.
이때에도 실제 프로덕션에서 사용되는 메서드만 정의되어 있다면 테스트 더블을 만들기에도 수월할 거라 생각합니다.

x86과 ARM의 차이에 대해 설명해주시겠어요?

CPU에는 CPU가 사용하는 명령어 집합체, 즉 ISA (Instruction set architecture)가 있습니다.
대표적인 ISA로는 인텔과 AMD의 x86이 있습니다.
이들이 독주하며 소프트웨어 회사들도 이 ISA에 맞춰 프로그램을 개발해왔습니다.
또다른 ISA로는 ARM이 있습니다.
ARM은 인텔, AMD와 달리 CPU를 뼈대까지만 설계한뒤 이를 제공하는 영업방식을 취했습니다.
2007년 애플의 아이폰이 출시되었는데, 애플은 ARM 기반으로 AP를 설계했습니다.
이후 경량화, 저전력 수요가 커지며 ARM의 개방적이고 유연한 사업 모델이 득세하게 되었습니다.
최근 애플의 M1칩, AWS의 t4 Family 인스턴스 등이 높은 성능과 저전력으로 시장에서 좋은 반응을 얻고 있는데요,
이들은 ARM 기반으로 애플, AWS가 직접 설계한 칩입니다.
개인적으로 향후 더 많은 ARM 기반 칩들이 서버, 모바일 시장을 장악할 것으로 생각합니다.

git submodule을 사용해본 적 있으신가요?

Github public repository 내 민감정보를 비공개 처리하기 위해 사용해본 적 있습니다.
먼저 private repository를 만든 뒤, 그 안에 민감 정보를 담아두었습니다.
그 뒤, git submodule add 명령어를 이용해 private repository를 연결했습니다.
resources 경로 하위 경로에 연결해두었고, resources 내 application.yml에서는 서브 모듈 내 파일을 import 하는 문장만 남겨두었습니다.
public repository 에서 바라볼 때엔 커밋 아이디만 기록되고 내부 내용은 확인할 수 없음을 확인했습니다.
submodule에 변경이 발생했을 경우, 이를 git submodule foreach git pull 명령어로 반영한 뒤 push함으로써 동기화했습니다.
github actions, jenkins에서도 submodule checkout을 위한 token만 설정해두면 의도한대로 동작해서 큰 어려움은 없었습니다.

Jenkins를 사용해본 적 있으신가요?

EC2 인스턴스에 Jenkins를 구축하고, Pipeline Item을 생성해서 CI/CD 과정을 구현해본 적 있습니다.
빌드 시점에 메모리 부족으로 인해 Swap Memory를 추가해주었고, Jenkins Credentials로 해당 리포지토리 접근권한이 있는 토큰을 설정해두었습니다.
develop, main 두 가지 브랜치에 대해서 프론트 백엔드를 나누어 merge 발생 시 Github Webhook을 Jenkins로 전달하여 배포 자동화를 구축한 바 있습니다.
특기할만한 점은 Github private repository에 Jenkinsfile을 관리했다는 점입니다.
학습 과정에 있었기 때문에 형상관리가 된다는 점, 함께 프로젝트를 진행하는 개발자들간에 배포 내용이 공유된다는 점이 큰 장점으로 느껴졌습니다.
그러나 실무에서 배포와 개발의 역할을 더 세분화한다면 Jenkinsfile이 형상관리 대상이 되는 것이 적절할지,
추가로 형상관리 대상이더라도 인프라 팀이 아닌 개발팀에도 이러한 정보가 공개되는 것이 적절할지에 대해서는 상황에 따라 달라질 수도 있을 거라는 생각을 했습니다.
