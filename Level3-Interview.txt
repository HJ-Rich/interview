.class 파일처럼 형상관리 대상이 아닌 파일이 commit & push 되었을 때 어떻게 대처할 수 있을까요?

git rm 명령어를 사용하여 해결할 수 있습니다.
git rm 명령어는 index에서 제거하는 명령입니다.
--cached 옵션을 추가하여 working tree에서도 삭제할지, 아니면 남겨둘지 선택할 수 있습니다.
index에서 삭제하는 작업을 완료한 후에는 .gitignore 설정을 통해 재차 staging 되지 않도록 처리해두어야 합니다.

서버 접속 정보나 저작권 위반 소지가 있는 데이터가 리모트에 push된 채로 작업하다가 뒤늦게 발견했다면 어떻게 대처할 수 있을까요?

크게 세 가지 작업을 진행해야 합니다.
첫째로 형상관리 대상에서 제외해야 합니다.
둘째로 이전 커밋 히스토리들을 Rewrite해야 합니다.
셋째로 유출된 접속 정보를 파기하거나 변경해야 합니다.
첫번째와 두번째 작업은 git filter-branch 명령어와 --index-filter 옵션을 이용해 수행할 수 있습니다.
private 리포지토리에서 진행하던 사이드 프로젝트를 public으로 전환하는 과정에서
민감 정보를 담은 application.yml 파일을 모든 커밋 이력에서 제거하기 위해 filter-branch 명령어를 사용해봤습니다.
git-scm 문서에서도 반복 강조하는 부분이 이 명령어는 성능 이슈도 있고 자잘한 버그도 있으니 가급적 사용하지 말라고 합니다.
제가 이 명령어를 사용해야 했던 상황은 재작성되어야 할 커밋 이력이 많지 않았기에 괜찮았지만
만약 상당히 많은 커밋들을 모두 재작성해야 하는 상황이었다면 그래도 이 명령어를 사용했겠지만 많이 부담스러웠을 것 같습니다.

자신만의 라이브러리를 만들어 배포해본 경험이 있나요?

HttpServletRequest를 전달받아, Bearer Token을 반환하는 라이브러리를 만들어서 jitpack으로 배포해보았습니다.
여러 프로젝트에서 반복해서 사용되는 코드인데, 매번 복사 붙여넣기로 옮겨야하는 점이 번거로웠습니다.
또한 한 곳에서 관리되지 않기에, 수정이 필요할 경우 모든 프로젝트에 각각 들어가서 수정해야 하는 점도 불편했습니다.
Spring Security OAuth 라이브러리에서 제공하는 DefaultBearerTokenResolver를 일부 수정해서 만들었습니다.
다른 사람도 사용할 수 있게 배포한다고 생각하니 테스트 코드나 변수명, 클래스명 등등 모두 더 신경써서 작성하게 되는 경험을 해봤습니다.

정적 분석 도구를 사용해본 경험이 있나요?

Github Actions, Jacoco, SonarQube를 이용한 정적 분석을 수행해본 적 있습니다.
EC2 인스턴스를 생성하고, SonarQube, PostgreSQL을 설치해서 구축한뒤,
Github Actions와 연동하여 PR 생성, 머지 시점마다 자동으로 정적 분석을 수행하게 구축해보았습니다.
SonarQube의 인상적이었던 정적 분석 중 한 가지는
팀내 의견 조율을 위해 일시적으로 @Disabled 처리해두었던 테스트에 대해
왜 @Disabled 처리했는지 주석으로 설명을 달거나 아니면 제거하라는 제안이었습니다.
당시에 소규모 팀 프로젝트였기에 모두가 이 상황에 대해 인지하고 있긴 했지만,
원칙적으로 다른 개발자들과의 소통이라는 측면에서 충분히 일리있는 제안으로 이해되었고,
이런 부분까지 탐지하고 제안해준다는 점이 인상깊었습니다.
SonarQube에서 Issue로 제기해준 내용들을 살펴보며 더 깨끗한 코드를 작성할 수 있게 될 뿐만 아니라
다른 개발자들과의 더 나은 협업을 위해서 어떻게 코드를 작성해야하는지 더 이해할 수 있었습니다.

CI 가 무엇인가요? 경험해본 적 있으신가요?

CI는 Continuous Integration 의 약자로 2010년 제즈 험블과 데이빗 팔리에 의해 제안되었습니다.
CI의 핵심 개념은 여러 개발자들이 함께 일하는 시스템의 상태에 대해 공유된 정확한 관점을 유지하고 배포하는 것입니다.
최초 제안자인 데이빗 팔리의 CI는 브랜칭 전략을 사용할 경우 이를 CI로 인정할 수 없다는 다소 엄격한 스탠스인데요,
프로젝트를 진행하며 경험한 CI는 이보다는 다소 완화된 CI 정책을 적용하여 진행해보았습니다.
먼저 브랜칭 전략을 사용하되 Github Actions를 이용해 PR 생성 시 자동으로 머지된 결과로 빌드 및 테스트가 수행되고 피드백을 받을 수 있게 구성했습니다.
또한 기능 개발이 진행중이더라도 해당 브랜치를 드러냄으로써, 작업중인 내용을 다른 개발자들도 확인할 수 있게 했습니다.
핵심 기능에 대해서는 Draft 상태로 PR을 Open해두고 추가작업을 하는 식으로 더 잦은 CI를 시도해본 바 있습니다.
현재 작업중인 코드가 병합되어서도 잘 동작하리라는 추측이 아닌 확인을 해야 한다는 CI 개념의 가치는 충분히 공감됩니다.
또한 자동화된 병합 및 테스트, 피드백이 구성되었을 때 이를 통한 빠른 수정은 개발 프로세스에 큰 도움이 되었습니다.

데이빗 팔리는 왜 Git Flow가 CI/CD로 인정하지 않았나요?

첫째로 피드백이 늦다는 점입니다.
Git Flow는 기능단위별로 브랜치를 생성해서 해당 브랜치에서 개발을 완료한 후에 병합시키는 작업 방식입니다.
이 경우, 해당 브랜치의 기능개발이 완료된 이후에야 병합하고, 피드백을 받을 수 있게 됩니다.
이처럼 늦은 피드백은 잘못 개발하고 있었을 경우 큰 비용으로 이어지기도 하고, 병합 시점에 많은 비용을 치러야하기도 합니다.
그리고 이는 곧 배포의 지연으로 이어지기에 크리티컬한 이슈라 할 수 있습니다.
반면 데이빗 팔리의 CI는 최소 하루에 한 번, 실제론 하루에도 여러차례 pull, push를 하며 빠르게 피드백을 받는 것을 의미합니다.
둘째로 Git Flow는 변화를 숨긴다는 점입니다.
개발자들의 협업의 최종관심사는 고객에게 전달되는 main 브랜치 하나인데, 안정성을 위해 변화를 숨기고 속도를 양보하는 것이 데이빗 팔리가 바라보는 Git Flow입니다.
서로 다른 feature 브랜치에서 개발을 진행하면 서로 어떤 변경이 있는지, 이들간 충돌은 없는지 병합 시점이 되어서야 확인할 수 있게 됩니다.
반면 데이빗 팔리의 CI는 하루에도 몇번씩, 협업 대상 리모트에 pull, push를 수행하기에,
다른 개발자들의 개발 내용도 수시로 확인하며 변화가 드러나게 되고, 이러한 드러난 변화가 배포해도 안전하다는 신호를 전달한다는 것이 데이빗 팔리의 주장입니다.

JpaRepository 대신 Repository를 사용한 이유가 있나요?

첫째로 필요한 메시지만 개방하기 위함이었습니다.
객체의 개방된 메서드들은 각각 책임을 의미하고, 이 책임이 모여 하나의 역할을 이루게 됩니다.
따라서 어떤 메서드가 열려있는지는 해당 객체를 정의내리는 중요한 지표라고 할 수 있습니다.
JpaRepository를 확장할 경우 프로덕션에서 사용되는지 여부와 상관 없이 기본으로 20여개의 메서드가 개방됩니다.
반면 Repository를 확장할 경우, 실제 프로덕션에서 사용되는 메서드만 선언해서 사용해야 합니다.
이처럼 실제 사용되는, 실제 필요한 메서드만 개방하는 것은 다른 개발자들에게도 이 객체의 역할을 전달하는 역할을 할 수 있다고 생각합니다.
둘째로 명세로서의 인터페이스를 충실하게 유지하기 위함이었습니다.
JpaRepository를 확장하는 클래스 역시 인터페이스인데,
사용하지 않는 메서드들이 정의되어 있다면, 해당 인터페이스의 규약을 제대로 전달하지 못하는 것이라 생각했습니다.
마지막으로 테스트 더블 생성 용이성을 가져가기 위함이었습니다.
직접 경험해보진 못했지만 CQRS 관련 테스트를 위해선 Repository의 테스트 더블을 만들 일이 있다고 들었습니다.
이때에도 실제 프로덕션에서 사용되는 메서드만 정의되어 있다면 테스트 더블을 만들기에도 수월할 거라 생각합니다.

x86과 ARM의 차이에 대해 설명해주시겠어요?

CPU에는 CPU가 사용하는 명령어 집합체, 즉 ISA (Instruction set architecture)가 있습니다.
대표적인 ISA로는 인텔과 AMD의 x86이 있습니다.
이들이 독주하며 소프트웨어 회사들도 이 ISA에 맞춰 프로그램을 개발해왔습니다.
또다른 ISA로는 ARM이 있습니다.
ARM은 인텔, AMD와 달리 CPU를 뼈대까지만 설계한뒤 이를 제공하는 영업방식을 취했습니다.
2007년 애플의 아이폰이 출시되었는데, 애플은 ARM 기반으로 AP를 설계했습니다.
이후 경량화, 저전력 수요가 커지며 ARM의 개방적이고 유연한 사업 모델이 득세하게 되었습니다.
최근 애플의 M1칩, AWS의 t4 Family 인스턴스 등이 높은 성능과 저전력으로 시장에서 좋은 반응을 얻고 있는데요,
이들은 ARM 기반으로 애플, AWS가 직접 설계한 칩입니다.
개인적으로 향후 더 많은 ARM 기반 칩들이 서버, 모바일 시장을 장악할 것으로 생각합니다.

git submodule을 사용해본 적 있으신가요?

Github public repository 내 민감정보를 비공개 처리하기 위해 사용해본 적 있습니다.
먼저 private repository를 만든 뒤, 그 안에 민감 정보를 담아두었습니다.
그 뒤, git submodule add 명령어를 이용해 private repository를 연결했습니다.
resources 경로 하위 경로에 연결해두었고, resources 내 application.yml에서는 서브 모듈 내 파일을 import 하는 문장만 남겨두었습니다.
public repository 에서 바라볼 때엔 커밋 아이디만 기록되고 내부 내용은 확인할 수 없음을 확인했습니다.
submodule에 변경이 발생했을 경우, 이를 git submodule foreach git pull 명령어로 반영한 뒤 push함으로써 동기화했습니다.
github actions, jenkins에서도 submodule checkout을 위한 token만 설정해두면 의도한대로 동작해서 큰 어려움은 없었습니다.

Jenkins를 사용해본 적 있으신가요?

EC2 인스턴스에 Jenkins를 구축하고, Pipeline Item을 생성해서 CI/CD 과정을 구현해본 적 있습니다.
빌드 시점에 메모리 부족으로 인해 Swap Memory를 추가해주었고, Jenkins Credentials로 해당 리포지토리 접근권한이 있는 토큰을 설정해두었습니다.
develop, main 두 가지 브랜치에 대해서 프론트 백엔드를 나누어 merge 발생 시 Github Webhook을 Jenkins로 전달하여 배포 자동화를 구축한 바 있습니다.
특기할만한 점은 Github private repository에 Jenkinsfile을 관리했다는 점입니다.
학습 과정에 있었기 때문에 형상관리가 된다는 점, 함께 프로젝트를 진행하는 개발자들간에 배포 내용이 공유된다는 점이 큰 장점으로 느껴졌습니다.
그러나 실무에서 배포와 개발의 역할을 더 세분화한다면 Jenkinsfile이 형상관리 대상이 되는 것이 적절할지,
추가로 형상관리 대상이더라도 인프라 팀이 아닌 개발팀에도 이러한 정보가 공개되는 것이 적절할지에 대해서는 상황에 따라 달라질 수도 있을 거라는 생각을 했습니다.

nginx가 무엇인가요? 사용해본 적 있으신가요?

nginx는 현재 가장 전 세계에서 가장 높은 30% 이상의 점유율을 지닌 웹서버입니다.
리버스 프록시, 게이트웨이, 로드밸런싱 등 다양한 기능도 함께 제공하고
아파치에 비해 적은 메모리 사용량, 더 높은 TPS로 인해 더 많은 선택을 받고 있습니다.
EC2 인스턴스에 nginx를 설치하고, 도메인을 적용하고, SSL 인증서를 발급받아 HTTPS 를 적용해본 적 있습니다.
nginx 설정으로는 location과 proxy_pass설정을 이용해 프론트엔드와 백엔드 API를 분기처리하여
Same-Origin을 유지함으로써 CORS 설정이 불필요하도록 아키텍처를 구성해보았습니다.

테스트 격리를 어떻게 하셨나요?

@AfterEach 메서드를 구성해서 각 테스트 메서드가 수행된 이후에 모든 데이터를 제거하고 PK를 1로 되돌리도록 했습니다.
다른 선택지로는 DirtiesContext를 사용하는 것과 @Sql 애너테이션을 사용하는 것과 @Transactional 애너테이션을 사용하는 것이 있었습니다.
DirtiesContext를 사용할 경우 매번 ContextCaching이 되지 않아 테스트 비용이 너무 커지는 문제가 있어 선택하지 않았습니다.
@Sql 애너테이션을 사용할 경우, 테스트 코드에 변경이 생길 때마다 파일도 함께 변경되어야 하고, 관리에 어려움이 있어 선택하지 않았습니다.
@Transactional 애너테이션을 사용할 경우, 프로덕션에서의 트랜잭션을 온전히 테스트할 수 없는 문제가 있어 선택하지 않았습니다.
최종 선택지는 DatabaseCleaner를 직접 구현하는 것이었는데, EntityManager로부터 Session을 직접 얻어서,
Native Query로 외래키 제약조건 해제, truncate, pk 1로 돌리기, 외래키 제약 조건 설정을 수행하도록 구성하는 것이었습니다.

왜 @Transactional 애너테이션을 테스트에서 사용하면 프로덕션의 트랜잭션을 온전히 테스트할 수 없다고 생각하시나요?

프로덕션에서 @Transactional 애너테이션을 누락하여 트랜잭션이 생성되지 않을 경우,
변경 감지 및 데이터베이스 동기화가 이루어지지 않게 됩니다.
그러나 이 코드에 대한 테스트 과정에서 @Transactional 애너테이션을 사용하게 된다면
테스트 대상이 되는 비즈니스 로직이 수행되는 동안 트랜잭션이 생기게 되어 프로덕션과 달리 변경 감지 및 데이터베이스 동기화가 이루어집니다.
실제로 팀 프로젝트중 프로덕션에 @Transactional 애너테이션을 누락하고
테스트 코드에서는 @SpringBootTest와 @Transactional 애너테이션을 사용해서 이로 인한 이슈를 경험한 적이 있습니다.
최초 로그인 여부를 반환하는 API 가 항상 최초 로그인이라고 true를 반환하는 이슈였는데,
프로덕션에서 @Transactional 애너테이션이 누락되어 false로 바뀐 boolean 값에 대한 변경 감지 및 동기화가 진행되지 않은 것이었습니다.
이 경험 이후로 테스트 격리 목적으로 @Transactional 애너테이션을 사용하는 것이 초래할 수 있는 위험에 대해 인식하게 되어
다른 테스트 격리 방법을 찾아보는 것이 낫겠다고 판단하게 되었습니다.

HTTPS 에 대해 설명해주세요

Secure Socket Layer 위의 HTTP 통신입니다.
암호화된 통신을 주고 받기 위해 Client와 Server 양 당사자는 대칭키를 가지고 있어야 하는데,
이 대칭키를 안전하게 전달하기 위해 비대칭키 방식을 사용합니다.
Client Hello와 Server Hello 과정을 통해 Server의 인증서를 응답받고,
이를 브라우저에 내장된 CA의 공개키로 복호화하여 Server의 공개키를 얻습니다.
두 번의 Hello에서 생성했던 난수를 이용해 premaster 를 생성하고 이를 Server의 공개키로 암호화해서 전송합니다.
이와 같은 과정을 거쳐서 이후에는 대칭키로 암호화 통신을 주고받을 수 있게 되는데요,
이러한 Secure Socket Layer 위에 FTP 통신을 하면 SFTP, Shell 통신을 하면 SSH가 됩니다.

공개키와 개인키에 대해 설명해주세요

암복호화에 동일한 키가 사용되는 대칭키 방식과 달리
암복호화에 각각 다른 키가 사용되기에 비대칭키라고 부르기도 합니다.
공개키로 암호화된 내용은 개인키로만 복호화 가능합니다.
이를 이용해 서버측에선 자신에게 데이터를 전송하고자 하는 클라이언트에게 자신의 공개키를 이용해 암호화하여 전송하도록 하면 됩니다.
HTTPS 통신을 위해 양 당사자가 대칭키를 지니게 handshake 하는 과정에서 비대칭키 방식이 사용됩니다.
리눅스 환경에서는 ssh-keygen 명령어를 이용해서 키 페어를 생성할 수 있습니다.
AWS, Oracle Cloud에서도 안전하게 SSH 통신을 하기 위한 수단으로 공개키, 개인키를 사용할 수 있습니다.

OAuth에 대해 설명해주세요

OAuth 는 Open Authorization의 약자입니다.
인터넷 사용자가 자신의 비밀번호를 제공하지 않고 타 사이트에 있는 자신의 정보에 대한 접근 권한을 부여하는 개방형 표준입니다.
주로 자원을 지닌 사이트의 인증 서버로 리디렉팅 된 사용자가 code를 발급받아 이를 자원을 요청하는 사이트에 전달하면
사이트는 자원을 지닌 서버의 인증 서버로 code를 가져가 accessToken으로 교환환 뒤,
이를 자원을 지닌 서버의 자원 서버로 가서 자원을 받아오는 프로세스로 이루어집니다.
이를 통해 여러 애플리케이션을 통합하여 사용하는 것이 가능하게 됩니다.
